---
layout: archive
title: " "
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
======

* *2020 - Present* \\
&nbsp;&nbsp;&nbsp; PhD, **Continual Learning for Generative Models**\\
&nbsp;&nbsp;&nbsp; [Computational Intelligence](https://cs.vu.nl/ci/) group, Vrije Universiteit Amsterdam (VU)\\
&nbsp;&nbsp;&nbsp; Supervised by: Jakub Tomczak (VU), Max Welling (UvA), Guszti Eiben (VU)

* *2017 - 2019* \\
&nbsp;&nbsp;&nbsp; MSc, **Statistical Learning Theory** (double degree)\\
&nbsp;&nbsp;&nbsp; [Higher School of Economics](https://www.hse.ru/en/ma/sltheory/) and
[Skoltech](https://www.skoltech.ru/en/education/msc-programs/ds/slt/)\\
&nbsp;&nbsp;&nbsp; Thesis: Bayesian Generative Models for Knowledge Transfer in Deep Neural Networks on MRI Data \\
&nbsp;&nbsp;&nbsp; Supervised by: Evgeny Burnaev \\
&nbsp;&nbsp;&nbsp; GPA:  8.65/10 (HSE); 4.74/5 (Skoltech)
 
* *2013 - 2017* \\
&nbsp;&nbsp;&nbsp; BSc, **Mathematical Methods in Economic Analysis**\\
&nbsp;&nbsp;&nbsp; [Higher School of Economics](https://www.hse.ru/en/ba/economics)\\
&nbsp;&nbsp;&nbsp; Thesis: Comparing Forecasting Power of Bayesian VAR with 1-d Time Series Models. \\
&nbsp;&nbsp;&nbsp; Supervised by: Boris Demeshev \\
&nbsp;&nbsp;&nbsp; GPA: 8.88/10

* *2016* \\
&nbsp;&nbsp;&nbsp; Exchange program, Erasmus School of Economics \\
&nbsp;&nbsp;&nbsp; Erasmus University Rotterdam, the Netherlands

Work experience
======
* *February 2024 - July 2024*\\
  &nbsp;&nbsp;&nbsp; **Assosiate Researcher** \\
  &nbsp;&nbsp;&nbsp; [Microsoft, AI4Science](https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/), Amsterdam\\
* *May 2023 - August 2023*\\
  &nbsp;&nbsp;&nbsp; **Research Intern** \\
  &nbsp;&nbsp;&nbsp; [Microsoft, AI4Science](https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/), Cambridge\\
  Training strictly local equivariant machine learning force field models with extended cutoff radius.
  <!-- Strictly local equivariant MLFF has gathered attentino for its remarcable speed and scalability. This advantage stems from their iheret parallelizaility during deeplyment. Nonetheless, specific tasks demand an expanded local cutoff radius to account for the long-range interactions. Accomplishing this expansion has proven to be challeging, primarily due to two significant limitations: increased memory consumption and poor training dynamics. During this internship we worked towards identyfying and addressing these issues. -->
  
* *July 2021 - October 2021*\\
  &nbsp;&nbsp;&nbsp; **Research Intern** \\
  &nbsp;&nbsp;&nbsp; [Qualcomm AI Research](https://www.qualcomm.com/research/artificial-intelligence/ai-research), Amsterdam\\
  Worked on compressed sensing with unknown orientation. See our [ICML paper](https://arxiv.org/abs/2206.14069). 
  
* *July 2019 - August 2020*\\
&nbsp;&nbsp;&nbsp; **Junior Research Engineer** \\
&nbsp;&nbsp;&nbsp; Skoltech, Moscow\\
&nbsp;&nbsp;&nbsp; Supervised by Evgeny Burnaev

* *Summer 2018* \\
&nbsp;&nbsp;&nbsp; **Deep Learning Intern**\\
&nbsp;&nbsp;&nbsp; NVIDIA, Moscow\\
&nbsp;&nbsp;&nbsp; Developed pipeline for online detection of creatures in the video games, based on deep neural network
  
* *2017 - 2018* \\
&nbsp;&nbsp;&nbsp; **Web Analyst**\\
&nbsp;&nbsp;&nbsp; Tinkoff bank, Moscow\\
&nbsp;&nbsp;&nbsp; Impact evaluation for online ads, anomaly detection in user behavior, A\B-testing for landing pages optimization 

[Teaching](https://akuzina.github.io/teaching/)
======
  
